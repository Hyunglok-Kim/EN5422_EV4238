{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework #7: Stacking and Boosting#\n",
        "\n",
        "# Problem 1: Stacking for Kaggle\n",
        "\n",
        "You are to make at least one official entry in the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview) Kaggle contest **using stacking or model averaging**; at least one component model must be a boosting model.\n",
        "\n",
        "- You will need to register in Kaggle (its free)\n",
        "- Read the details of the contest. Understand the data and evaluation function.\n",
        "- Make at least one submission that uses **stacking or model averaging**.\n",
        "- If you get a score on the public leaderboard of $\\text{RMSE}<0.50$ (note RMSE is calculated on the log scale), you receive full credit, otherwise, you'll lose 10 points.\n",
        "    - I'll allow [teaming](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/team). Each team member can produce one component model and then use stacking or model averaging to combine predictions.\n",
        "    - You don't need to team, but must still combine multiple models. At least one of the component models should be boosting.\n",
        "- Each person submit the following in Canvas:\n",
        "    - Code (if teaming, your code and the shared stacking code)\n",
        "    - kaggle name (or team name) so we can ensure you had a valid submission.\n",
        "    - your score and current ranking on the kaggle leaderboard\n",
        "- Top 5 scores get 2 bonus points\n",
        "    - Teams will split their bonus points among team members\n",
        "\n"
      ],
      "metadata": {
        "id": "_3-dYVwupZ-3"
      }
    }
  ]
}