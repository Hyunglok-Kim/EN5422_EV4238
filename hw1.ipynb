{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMlmDOofwBuncNXa8+ixUYt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Homework #1: Supervised Learning\n","\n","**Your Name Here**\n","<br>\n","Due: Tue, Sept 12 | Fall 2023 | GIST"],"metadata":{"id":"2xtfLiUitULz"}},{"cell_type":"markdown","source":["### Problem 1.1: Evaluating a Regression Model\n","\n","a. Create a set of functions to generate data from the following distributions:\n","\\begin{align*}\n","X &\\sim \\mathcal{N}(0, 1) \\\\\n","Y &= -1 + .5X + .2X^2 + \\epsilon \\\\\n","\\epsilon &\\sim \\mathcal{N}(0,\\, \\sigma)\n","\\end{align*}"],"metadata":{"id":"1AJaN92ytM9-"}},{"cell_type":"code","source":["# Add solution here\n","# First you need to import all the necessary library such as numpy and random\n","import numpy as np\n","import random"],"metadata":{"id":"-xo4RM7XuFO2","executionInfo":{"status":"ok","timestamp":1692632692455,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["b. Simulate $n=100$ realizations from these distributions using $\\sigma=3$. Produce a scatterplot and draw the true regression line $f(x) = E[Y \\mid X=x]$. Use `random.seed(321)` prior to generating the data."],"metadata":{"id":"NRSGw1Nbut0x"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"gBNBFdyhuxhK","executionInfo":{"status":"ok","timestamp":1692632692456,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["c. Fit three polynomial regression models using least squares: linear, quadratic, and cubic. Produce another scatterplot, add the fitted lines and true population line $f(x)$  using different colors, and add a legend that maps the line color to a model.\n","\n","    - Note: Notice that while the true model is quadratic, we are also fitting linear (less complex) and cubic (more complex) models."],"metadata":{"id":"Kw3IOeaKuwuQ"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"Ky4CseMeu74N","executionInfo":{"status":"ok","timestamp":1692632692457,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["d. Simulate a test data set of $10000$ observations from the same distributions. Use `random.seed(321)` prior to generating the test data. Calculate the estimated mean squared error (MSE) for each model.\n","Are the results as expected?"],"metadata":{"id":"o0mzl89Wu6Xu"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"CpPdVWC3v-ko","executionInfo":{"status":"ok","timestamp":1692632692457,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["e. What is the best achievable MSE? That is, what is the MSE if the true $f(x)$ was used to evaluate the test set? How close does the best method come to achieving the optimum?"],"metadata":{"id":"YI4esg9EwBAq"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"MPlhYOJ3wEPb","executionInfo":{"status":"ok","timestamp":1692632692457,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["f. The MSE scores obtained in part *d* came from one realization of training data. Here will we explore how much variation there is in the MSE scores by replicating the simulation many times.\n","    \n","    - Re-run the same simulation in part *d* 100 times.\n","    - Create kernel density plots (you choose bandwidth) of the resulting MSE values for each model.\n","    - Use `random.seed(613)` prior to running the simulation and do not set the seed in any other places."],"metadata":{"id":"bvbghQV-wLGQ"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"bN6H11nzwMOw","executionInfo":{"status":"ok","timestamp":1692632692457,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["g. Show a count of how many times each model was the best. That is, out of the 100 simulations, count how many times each model had the lowest MSE."],"metadata":{"id":"cgz-UlIzwUJ-"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"nhl45lI8wWvs","executionInfo":{"status":"ok","timestamp":1692632692458,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["h. Repeat the simulation in part *g*, but use $\\sigma=2$. Report the number of times each model was best (you do not need to produce any plots). Use the same `random.seed(321)` prior to running the simulation and do not set the seed in any other places."],"metadata":{"id":"InTEKqtHwYJg"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"U3kmDH5ow0OG","executionInfo":{"status":"ok","timestamp":1692632692458,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["i. Repeat *g*, but now use $\\sigma=4$ and $n=200$."],"metadata":{"id":"MEtNN4kyw1tN"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"CPVFwqH8w4aF","executionInfo":{"status":"ok","timestamp":1692632692458,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["j. Describe the effects $\\sigma$ and $n$ has on selection of the best model? Why is the *true* model form (i.e., quadratic) not always the *best* model to use when prediction is the goal?\n","\n","<div class=\"solution\">\n","When the training data is very noisy (i.e., high $\\sigma$ value), the quadratic/cubic model's model parameters are not accurately estimated. It was also shown in *Question C* that the quadratic/cubic model's patterns are actually the opposite of the true model (convex vs. concave). However, when the $\\sigma$ of the error model approaches 0, the quadratic model's parameters will approach the true equation: -1 + 0.5*x + 0.2*x^2. On the other hand, if $\\sigma$ is larger than a certain value, the linear model will perform better than the quadratic or cubic model. If $n$ is small, the MSE value can be biased because of not enough data for training, so that can affect our selection of the best model.\n","</div>"],"metadata":{"id":"Lx859RpUw5xM"}},{"cell_type":"code","source":["# Add solution here"],"metadata":{"id":"l5PPBG8Kw-LZ","executionInfo":{"status":"ok","timestamp":1692632692458,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyung","userId":"13878237671287180337"}}},"execution_count":10,"outputs":[]}]}