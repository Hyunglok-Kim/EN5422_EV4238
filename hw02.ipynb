{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2.1: Bootstrapping\n",
        "\n",
        "Bootstrap resampling can be used to quantify the uncertainty in a fitted curve.\n",
        "\n",
        "a. Create a set of functions to generate data from the following distributions:\n",
        "\n",
        "\\begin{align*}\n",
        "X &\\sim \\mathcal{U}(0, 2) \\qquad \\text{Uniform in $[0,2]$}\\\\\n",
        "Y &= 1 + 2x + 5\\sin(5x) + \\epsilon \\\\\n",
        "\\epsilon &\\sim \\mathcal{N}(0,\\, \\sigma=2.5)\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "7PyE3s7M5QCF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DsYYrNw-5Mtz"
      },
      "outputs": [],
      "source": [
        "# Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Simulate $n=100$ realizations from these distributions. Produce a scatterplot and draw the true regression line $f(x) = E[Y \\mid X=x]$. Use `numpy.random.seed(*321*)` prior to generating the data."
      ],
      "metadata": {
        "id": "LeJwOWhb53nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here"
      ],
      "metadata": {
        "id": "QXN8BM3r57z7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Now fit a 5th degree polynomial. Produce a scatterplot and draw the *estimated* regression curve."
      ],
      "metadata": {
        "id": "ASjZYtyH6Fb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here"
      ],
      "metadata": {
        "id": "UzoTzNJF6Epa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Draw $200$ bootstrap samples, fit a 5th degree polynomial to each bootstrap sample, and make predictions at `evalpts = np.linspace(0, 2, 100)`\n",
        "    - Set the seed (use `numpy.random.seed(321)`) so your results are reproducible.\n",
        "    - Produce a scatterplot and add the $200$ bootstrap curves."
      ],
      "metadata": {
        "id": "ucWwpVDm6JN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here"
      ],
      "metadata": {
        "id": "7laBg0HC6OT8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Calculate the pointwise 95% confidence intervals from the bootstrap samples. That is, for each $x \\in {\\rm evalpts}$, calculate the upper and lower limits such that only 5% of the curves fall outside the interval at $x$.\n",
        "    - Remake the plot from part *c*, but add the upper and lower boundaries from the 95% confidence intervals."
      ],
      "metadata": {
        "id": "ZU0GKvid6R38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here"
      ],
      "metadata": {
        "id": "jwX7jZhH6TWT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2.2: V-Fold cross-validation with $k$ nearest neighbors\n",
        "\n",
        "Run 10-fold cross-validation on the data generated in part 1b to select the optimal $k$ in a k-nearest neighbor (kNN) model. Then evaluate how well cross-validation performed by evaluating the performance on a large test set. The steps below will guide you.\n",
        "\n",
        "a. Use $10$-fold cross-validation to find the value of $k$ (i.e., neighborhood size) that provides the smallest cross-validated MSE using a kNN model. Search over $k=3,4,\\ldots, 50$.\n",
        "    - Use `numpy.random.seed(321)` prior to generating the folds to ensure the results are replicable.\n",
        "    - Report the optimal $k$ (as determined by cross-validation), the corresponding estimated MSE, and produce a plot with $k$ on the x-axis and the estimated MSE on the y-axis (optional: add 1-standard error bars)."
      ],
      "metadata": {
        "id": "Xwr5QhbA6WCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here"
      ],
      "metadata": {
        "id": "FKmjrv4S6e2A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. The $k$ (number of neighbors) in a kNN model determines the effective degrees of freedom *edf*. What is the optimal *edf*? Be sure to use the correct sample size when making this calculation. Produce a plot similar to that from part *a*, but use *edf* (effective degrees of freedom) on the x-axis."
      ],
      "metadata": {
        "id": "AP7AF9-j6gJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here"
      ],
      "metadata": {
        "id": "Dx9sXrcy6g-J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. After running cross-validation, a final model fit from *all* of the training data needs to be produced to make predictions. What value of $k$ would you choose? Why?"
      ],
      "metadata": {
        "id": "KoJxy8K06kOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer here"
      ],
      "metadata": {
        "id": "ij7RXJVb6mFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Now we will see how well cross-validation performed. Simulate a test data set of $50000$ observations from the same distributions. Use `numpy.random.seed(321)` prior to generating the test data.\n",
        "    - Fit a set of kNN models, using the full training data, and calculate the mean squared error (MSE) on the test data for each model. Use the same $k$ values in *a*.\n",
        "    - Report the optimal $k$, the corresponding *edf*, and MSE based on the test set."
      ],
      "metadata": {
        "id": "HgflO0WF6rjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Plot both the cross-validation estimated and true test error on the same plot. See Figure 5.6 in ISL (pg 208) as a guide (https://hastie.su.domains/ISLP/ISLP_website.pdf). - Produce two plots: one with $k$ on the x-axis and one with *edf* on the x-axis."
      ],
      "metadata": {
        "id": "ruSOspRh6ufM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here"
      ],
      "metadata": {
        "id": "rMvvOw3-68-O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. Based on the plots from *e*, does it appear that cross-validation worked as intended? How sensitive is the choice of $k$ on the resulting test MSE?      "
      ],
      "metadata": {
        "id": "49Jt_3iT7D6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer here"
      ],
      "metadata": {
        "id": "ZMd2R1ft7FG4"
      }
    }
  ]
}