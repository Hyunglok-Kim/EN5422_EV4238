{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 3.1: Optimal Tuning Parameters\n",
        "\n",
        "In cross-validation, we discussed choosing the tuning parameter values that minimized the cross-validation error. Another approach, called the \"one-standard error\" rule [ISL pg 214, ESL pg 61], uses the values corresponding to the least complex model whose cv error is within one standard error of the best model. The goal of this assignment is to compare these two rules.\n",
        "\n",
        "Simulate the data using the function in Python (make_friedman1 from scikit-learn) and fit Lasso regression models using the Lasso class from scikit-learn. The tuning parameter $\\lambda$ (corresponding to the penalty on the coefficient magnitude) is the one we will focus one. Generate training data, use k-fold cross-validation to get $\\lambda_{\\rm min}$ and $\\lambda_{\\rm 1SE}$, generate test data, make predictions for the test data, and compare performance of the two rules under a squared error loss using a hypothesis test.  \n",
        "\n",
        "Choose reasonable values for:\n",
        "\n",
        "- Number of cv folds ($K$)\n",
        "    - Note: you are free to use repeated CV, repeated hold-outs, or bootstrapping instead of plain cross-validation; just be sure to describe what do did so it will be easier to grade.\n",
        "- Number of training and test observations\n",
        "- Number of simulations\n",
        "- If everyone uses different values, we will be able to see how the results change over the different settings.\n",
        "- Don't forget to make your results reproducible (e.g., set seed)\n",
        "\n",
        "This pseudo code will get you started:"
      ],
      "metadata": {
        "id": "VTkT3MdP1RWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iORqGujO0dT7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_friedman1\n",
        "from sklearn.linear_model import LassoCV, RidgeCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#-- Settings\n",
        "n_train = # number of training obs\n",
        "n_test =  # number of test obs\n",
        "K =      # number of CV folds\n",
        "alpha =  # 1 for lasso and 0 for ridge\n",
        "M =      # number of simulations\n",
        "\n",
        "#-- Data Generating Function\n",
        "def getData(n):\n",
        "    return make_friedman1(n_samples=n, n_features=10, noise=2.0, random_state=None)\n",
        "\n",
        "# Initialize lists to store performance metrics\n",
        "mse_list = []\n",
        "\n",
        "np.random.seed(321)  # Set Seed Here\n",
        "\n",
        "for m in range(M):\n",
        "\n",
        "    # 1. Generate Training Data\n",
        "    X_train, y_train = getData(n_train)\n",
        "\n",
        "    # 2. Build Training Model using cross-validation\n",
        "    if alpha == 1:  # Lasso\n",
        "        model = LassoCV(cv=K).fit(X_train, y_train)\n",
        "    elif alpha == 0:  # Ridge\n",
        "        model = RidgeCV(cv=K).fit(X_train, y_train)\n",
        "\n",
        "    # 3. Get the alpha/lambda that minimizes CV error\n",
        "    optimal_alpha = model.alpha_\n",
        "\n",
        "    # 4. Generate Test Data\n",
        "    X_test, y_test = getData(n_test)\n",
        "\n",
        "    # 5. Predict y values for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 6. Evaluate predictions\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_list.append(mse)\n",
        "\n",
        "#-- Compare\n",
        "# Convert to numpy array for easier statistical analysis\n",
        "mse_array = np.array(mse_list)\n",
        "# Here, you can perform various statistical tests on mse_array or compare it with other methods."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Code for the simulation and performance results."
      ],
      "metadata": {
        "id": "kDNZuYxY45FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your answer here."
      ],
      "metadata": {
        "id": "nt4zIs1E5AGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Description and results of a hypothesis test comparing $\\lambda_{\\rm min}$ and $\\lambda_{\\rm 1SE}$."
      ],
      "metadata": {
        "id": "DBh-VA6O49j0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answere here."
      ],
      "metadata": {
        "id": "XBq_c5E65Gt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 3.2 Prediction Contest: Real Estate Pricing\n",
        "\n",
        "This problem uses the [realestate-train](https://github.com/Hyunglok-Kim/EN5422_EV4238/blob/main/realestate-train.csv) and [realestate-test](https://github.com/Hyunglok-Kim/EN5422_EV4238/blob/main/realestate-test.csv) (click on links for data).\n",
        "\n",
        "The goal of this contest is to predict sale price (in thousands) (`price` column) using an *elastic net* model. Evaluation of the test data will be based on the root mean squared error ${\\rm RMSE}= \\sqrt{\\frac{1}{m}\\sum_i (y_i - \\hat{y}_i)^2}$ for the $m$ test set observations.\n",
        "\n",
        "a. Use an *elastic net* model to predict the `price` of the test data. Submit a .csv file (ensure comma separated format) named `lastname_firstname.csv` that includes the column named *yhat* that is your estimates. We will use automated evaluation, so the format must be exact.\n",
        "\n",
        "    - You are free to use any tuning parameters\n",
        "\n",
        "    - You are free to use any data transformation or feature engineering\n",
        "    \n",
        "    - You will receive credit for a proper submission; the top five scores will receive 2 bonus points."
      ],
      "metadata": {
        "id": "ZBiqWrps5Qck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Show the code you used to transform the data. Note: there are some categorical predictors so at the least you will have to convert those to something numeric (e.g., one-hot or dummy coding)."
      ],
      "metadata": {
        "id": "-0Svt9WC6HnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your answer here."
      ],
      "metadata": {
        "id": "ePmWUbEp6JCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Report the $\\alpha$ and $\\lambda$ parameters you used to make your final predictions. Describe how you choose those tuning parameters and show supporting code."
      ],
      "metadata": {
        "id": "XIUOXjo46OPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "your answer here."
      ],
      "metadata": {
        "id": "E7f2IXi36QP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Report the anticipated performance of your method in terms of RMSE. We will see how close your performance assessment matches the actual value."
      ],
      "metadata": {
        "id": "OIEH4f5K6bDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your answer here."
      ],
      "metadata": {
        "id": "5PPEHSxX6YfX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}